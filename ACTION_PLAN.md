# ğŸ¯ Political Scraping + ETL Pipeline Action Plan

## ğŸ“Š Current Codebase Analysis

### âœ… **Existing Structure (Current State)**
- **Database Layer**: Supabase PostgreSQL integration with AIADMK-focused schema
- **Scrapers**: Individual platform scrapers (Facebook, YouTube, Instagram, Twitter, Reddit, Tamil News)  
- **Services**: API integration services (SerpAPI, Brave Search, Firecrawl, Apify)
- **Configuration**: Environment-based config management system
- **Main Engine**: AIADMK Intelligence Engine with orchestration capabilities

### âŒ **Current Limitations** 
- **Single Party Focus**: Only supports AIADMK (needs multi-competitor support)
- **No Stage-Based Processing**: Direct scraping without discovery/engagement separation
- **No Manual URL Support**: No interface for manual URL insertion
- **Limited Monitoring**: No scheduled monitoring of known sources
- **No Deduplication**: Missing URL/content deduplication logic
- **No Queue System**: No proper job queue management (Celery + Redis)

---

## ğŸ—‚ï¸ **Database Schema Transformation Plan**

### Stage 1: Core Tables Migration âœ…
- [x] **competitors**: Multi-party support (ADMK, DMK, BJP, NTK, PMK, TVK, DMDK)
- [x] **platforms**: Normalized platform management 
- [x] **keywords**: Per competitor Ã— platform keyword mapping
- [x] **sources**: Manual monitoring list (channels, accounts, websites)

### Stage 2: Pipeline Tables â³
- [ ] **stage_results**: Raw discovery data with deduplication
- [ ] **final_results**: Enriched engagement data with metrics
- [ ] **manual_queue**: User-inserted URLs before processing
- [ ] **monitoring_schedule**: Scheduled monitoring jobs

### Stage 3: Advanced Tables â³  
- [ ] **scraping_jobs**: Queue management with Celery integration
- [ ] **deduplication_cache**: URL/content similarity tracking
- [ ] **analytics_summary**: Pre-computed metrics for dashboards

---

## ğŸ”„ **2-Stage Pipeline Implementation**

### ğŸ” **Stage 1: Discovery Engine** â³
**Goal**: Find URLs from keywords/sources and store in staging

#### Discovery Methods:
- [ ] **SerpAPI Integration**: Search competitor keywords across platforms
- [ ] **Brave Search Integration**: Alternative web search for URL discovery  
- [ ] **Firecrawl Integration**: News website crawling for articles
- [ ] **Manual URL Queue**: User-submitted URLs via frontend
- [ ] **Source Monitoring**: Regular checks of known channels/accounts

#### Implementation Tasks:
- [ ] `discovery_engine.py`: Main discovery orchestrator
- [ ] `keyword_discovery.py`: SerpAPI/Brave search automation
- [ ] `source_monitoring.py`: Channel monitoring automation
- [ ] `manual_queue_processor.py`: Process user-submitted URLs
- [ ] `discovery_deduplication.py`: URL-level deduplication logic

### âš¡ **Stage 2: Engagement Engine** â³
**Goal**: Scrape engagement metrics from discovered URLs

#### Engagement Extraction:
- [ ] **Apify Integration**: Reliable scraping via specialized actors
- [ ] **Browser Automation**: Fallback scraping for complex cases
- [ ] **API Integration**: Direct platform APIs where available
- [ ] **Content Analysis**: Extract comments, shares, views, likes
- [ ] **Growth Tracking**: Multiple snapshots over time

#### Implementation Tasks:
- [ ] `engagement_engine.py`: Main engagement orchestrator
- [ ] `apify_integration.py`: Enhanced Apify service with queue support
- [ ] `browser_automation.py`: Playwright/Selenium fallback scrapers
- [ ] `engagement_deduplication.py`: Content-level similarity detection
- [ ] `metrics_calculator.py`: Engagement rate and trend calculations

---

## ğŸš€ **Queue System Implementation**

### âš™ï¸ **Celery + Redis Setup** â³
- [ ] **Redis Configuration**: Queue backend setup
- [ ] **Celery Workers**: Background task processing
- [ ] **Task Routing**: Discovery vs Engagement task separation
- [ ] **Error Handling**: Retry logic and dead letter queues
- [ ] **Monitoring**: Task status and performance tracking

#### Implementation Tasks:
- [ ] `celery_config.py`: Celery application setup
- [ ] `celery_tasks.py`: Task definitions for discovery/engagement
- [ ] `queue_manager.py`: Queue monitoring and management
- [ ] `worker_health.py`: Worker status and restart logic

---

## ğŸ“… **Manual & Monitoring Features**

### ğŸ–±ï¸ **Manual URL Management** â³
- [ ] **Frontend Interface**: Simple web UI for URL submission
- [ ] **Bulk Import**: CSV/Excel file upload for multiple URLs
- [ ] **URL Validation**: Check URL format and accessibility
- [ ] **Status Tracking**: Real-time processing status updates

### ğŸ“Š **Source Monitoring** â³
- [ ] **Channel Registration**: Add YouTube channels, FB pages, news sites
- [ ] **Scheduled Crawling**: Daily/weekly monitoring jobs
- [ ] **New Content Detection**: Compare against previous crawls
- [ ] **Alert System**: Notifications for high-engagement content

#### Implementation Tasks:
- [ ] `manual_interface.py`: Flask/FastAPI web interface
- [ ] `source_manager.py`: Channel/source registration system
- [ ] `monitoring_scheduler.py`: Cron-like job scheduling
- [ ] `alert_system.py`: Notification system for important content

---

## ğŸ”„ **Multi-Competitor Architecture**

### ğŸ›ï¸ **Competitor Management** â³
- [ ] **Dynamic Competitor Support**: Add/remove parties via configuration
- [ ] **Keyword Management**: Per-party keyword customization
- [ ] **Priority System**: Resource allocation based on importance
- [ ] **Cross-Competitor Analytics**: Comparative metrics and trends

#### Competitor Database:
- **ADMK**: à®…à®¤à®¿à®®à¯à®•, AIADMK, Edappadi Palaniswami, EPS
- **DMK**: à®¤à®¿à®®à¯à®•, DMK, Stalin, MK Stalin  
- **BJP**: à®ªà®¾à®œà®•, BJP, Tamil Nadu BJP
- **NTK**: à®¨à®¾à®®à¯ à®¤à®®à®¿à®´à®°à¯, NTK, Seeman
- **PMK**: à®ªà®Ÿà¯à®Ÿà®¾à®²à®¿, PMK, Anbumani Ramadoss
- **TVK**: à®¤à®³à®ªà®¤à®¿, TVK, Vijay
- **DMDK**: à®Ÿà®¿à®à®®à¯à®Ÿà®¿à®•à¯‡, DMDK, Premalatha Vijayakanth

#### Implementation Tasks:
- [ ] `competitor_manager.py`: Dynamic competitor management
- [ ] `keyword_optimizer.py`: AI-powered keyword suggestion
- [ ] `priority_allocator.py`: Resource distribution logic
- [ ] `competitor_analytics.py`: Cross-party comparison metrics

---

## ğŸ§¹ **Deduplication System**

### ğŸ” **Multi-Level Deduplication** â³

#### URL-Level (Hard Rules):
- [ ] **Canonical URL Normalization**: Remove tracking parameters
- [ ] **URL Similarity Detection**: Detect redirects and shortened URLs
- [ ] **Platform-Specific Logic**: Handle platform URL variations
- [ ] **Unique Constraint Enforcement**: Database-level duplicate prevention

#### Content-Level (Soft Rules): 
- [ ] **Text Similarity**: Trigram/cosine similarity for content matching
- [ ] **Image Hash Comparison**: Perceptual hashing for media content
- [ ] **Metadata Matching**: Title + author + date similarity
- [ ] **AI-Powered Detection**: LLM-based semantic similarity

#### Implementation Tasks:
- [ ] `url_normalizer.py`: URL cleaning and standardization
- [ ] `content_similarity.py`: Text and media similarity detection
- [ ] `dedup_engine.py`: Main deduplication orchestrator
- [ ] `similarity_cache.py`: Performance optimization with caching

---

## ğŸ“Š **Analytics & Reporting System**

### ğŸ“ˆ **Future Analytics Support** â³
- [ ] **Volume Metrics**: Mentions, posts, engagement over time
- [ ] **Content Analysis**: Keyword frequency, topic modeling
- [ ] **Sentiment Analysis**: Political sentiment tracking
- [ ] **Influence Metrics**: Channel ranking, reach analysis
- [ ] **Competitive Intelligence**: Share of voice, relative performance

#### Implementation Tasks:
- [ ] `analytics_engine.py`: Main analytics processor
- [ ] `sentiment_analyzer.py`: Tamil + English sentiment analysis
- [ ] `trend_detector.py`: Viral content and trend identification  
- [ ] `influence_calculator.py`: Channel authority and reach metrics
- [ ] `dashboard_data.py`: API endpoints for frontend dashboards

---

## ğŸ“± **Frontend Dashboard** (Optional)

### ğŸ–¥ï¸ **Web Interface** â³
- [ ] **Real-time Dashboard**: Live metrics and status updates
- [ ] **Manual URL Interface**: Submit URLs and monitor status
- [ ] **Analytics Views**: Charts, trends, competitor comparisons
- [ ] **Admin Panel**: System configuration and monitoring
- [ ] **Mobile Responsive**: Works on phones and tablets

#### Implementation Tasks:
- [ ] `dashboard_app.py`: Main Flask/FastAPI application
- [ ] `api_endpoints.py`: REST API for data access
- [ ] `frontend_templates/`: HTML/CSS/JS dashboard files
- [ ] `mobile_responsive.css`: Mobile optimization
- [ ] `real_time_updates.js`: WebSocket integration for live data

---

## ğŸ”§ **Testing & Quality Assurance**

### âœ… **Testing Strategy** â³
- [ ] **Unit Tests**: Individual component testing
- [ ] **Integration Tests**: End-to-end pipeline testing
- [ ] **Load Tests**: Performance under high volume
- [ ] **Data Quality Tests**: Deduplication accuracy validation
- [ ] **API Tests**: External service integration testing

#### Implementation Tasks:
- [ ] `test_discovery.py`: Discovery engine test suite
- [ ] `test_engagement.py`: Engagement scraping tests
- [ ] `test_deduplication.py`: Deduplication accuracy tests
- [ ] `test_performance.py`: Load and performance testing
- [ ] `test_data_quality.py`: Data validation and integrity tests

---

## ğŸ“‹ **Implementation Timeline**

### **Phase 1: Foundation (Weeks 1-2)** â³
- [ ] Database schema transformation
- [ ] Multi-competitor support
- [ ] Basic queue system setup
- [ ] URL deduplication logic

### **Phase 2: Core Pipeline (Weeks 3-4)** â³
- [ ] Discovery engine implementation
- [ ] Engagement engine enhancement
- [ ] Content deduplication system
- [ ] Manual URL interface

### **Phase 3: Monitoring & Analytics (Weeks 5-6)** â³
- [ ] Source monitoring system
- [ ] Basic analytics implementation
- [ ] Dashboard development
- [ ] Performance optimization

### **Phase 4: Advanced Features (Weeks 7-8)** â³
- [ ] AI-powered analytics
- [ ] Advanced deduplication
- [ ] Mobile dashboard
- [ ] Production deployment

---

## âœ… **Task Completion Tracking**

### ğŸ¯ **Current Status**: 15% Complete
- âœ… **Codebase Analysis**: Completed
- âœ… **Action Plan**: Completed  
- â³ **Database Migration**: In Progress
- âŒ **Queue System**: Not Started
- âŒ **Discovery Engine**: Not Started
- âŒ **Engagement Engine**: Not Started
- âŒ **Deduplication**: Not Started
- âŒ **Analytics**: Not Started
- âŒ **Frontend**: Not Started
- âŒ **Testing**: Not Started

---

## ğŸŒ **Web UI Requirements** â³

### ğŸ“Š **Admin Dashboard Interface** 
- [ ] **Competitor Management**: Add/edit/delete political competitors
- [ ] **Keyword Management**: Manage keywords per competitor per platform
- [ ] **Manual URL Insertion**: Submit URLs for immediate processing
- [ ] **Channel Monitoring**: Add/monitor social media channels and news sources
- [ ] **Real-time Status**: Live view of scraping progress and results
- [ ] **Analytics Dashboard**: Charts, metrics, competitor comparisons

### ğŸ”§ **Technical Requirements**
- [ ] **Frontend Framework**: React/Vue.js or Flask templates
- [ ] **Backend API**: FastAPI or Flask REST endpoints
- [ ] **Real-time Updates**: WebSocket integration for live data
- [ ] **Mobile Responsive**: Works on tablets and phones
- [ ] **Authentication**: Basic admin login system

---

## ğŸ“Š **Apify Integration Enhancement** â³

### ğŸ“ **Results Analysis** 
- [ ] **Analyze Apify results in Results folder**: Understand data structure
- [ ] **Field Mapping**: Map Apify fields to database schema
- [ ] **Data Validation**: Ensure data quality and completeness
- [ ] **Error Handling**: Process failed scraping attempts

---

## ğŸ—„ï¸ **Database Cleanup & Migration** â³

### ğŸ§¹ **Supabase Cleanup**
- [ ] **Delete unwanted tables**: Remove AIADMK-specific tables
- [ ] **Backup existing data**: Export current data before migration
- [ ] **Create normalized schema**: Implement multi-competitor tables
- [ ] **Data migration**: Move existing data to new structure

---

## ğŸ“¦ **Version Control Setup** â³

### ğŸ”§ **GitHub Integration**
- [ ] **Initialize Git repository**: Setup version control
- [ ] **Create GitHub repository**: Connect to remote repository
- [ ] **Setup .gitignore**: Exclude sensitive files and logs
- [ ] **Initial commit**: Commit current codebase
- [ ] **Branch strategy**: Setup development branches

---

## ğŸš¨ **Updated Implementation Priority**

### **Phase 0: Setup & Analysis (Week 1)** â³
- [ ] Analyze Apify results for field mapping
- [ ] Initialize GitHub repository for version control
- [ ] Clean up unwanted Supabase tables
- [ ] Update action plan with detailed tasks

### **Phase 1: Foundation (Weeks 1-2)** â³
- [ ] Database schema migration to multi-competitor
- [ ] Basic queue system setup (Celery + Redis)
- [ ] URL deduplication logic implementation
- [ ] Apify integration enhancement with proper field mapping

### **Phase 2: Core Pipeline (Weeks 2-3)** â³
- [ ] Discovery engine implementation
- [ ] Engagement engine enhancement
- [ ] Content deduplication system
- [ ] Basic web UI framework setup

### **Phase 3: Web Interface (Weeks 3-4)** â³
- [ ] Web UI for competitor management
- [ ] Web UI for keyword management  
- [ ] Web UI for manual URL insertion
- [ ] Web UI for channel monitoring
- [ ] Real-time dashboard implementation

### **Phase 4: Advanced Features (Weeks 4-5)** â³
- [ ] Source monitoring automation
- [ ] Analytics and reporting system
- [ ] Mobile-responsive design
- [ ] Performance optimization

### **Phase 5: Testing & Deployment (Week 5-6)** â³
- [ ] Comprehensive testing suite
- [ ] Load testing and optimization
- [ ] Production deployment setup
- [ ] Documentation and training

---

## âœ… **Detailed Task Completion Tracking**

### ğŸ¯ **Current Status**: 25% Complete

#### âœ… **Completed Tasks**
- [x] **Codebase Analysis**: Full analysis of existing system
- [x] **Action Plan Creation**: Comprehensive roadmap created  
- [x] **Task Breakdown**: Detailed implementation tasks identified

#### â³ **In Progress**
- [ ] **Action Plan Updates**: Adding new requirements and priorities

#### ğŸ”„ **Phase 0: Setup & Analysis** (0/4 completed)
- [ ] **Analyze Apify Results**: Understand data structure from Results folder
- [ ] **GitHub Repository Setup**: Initialize version control
- [ ] **Supabase Table Cleanup**: Remove unwanted tables
- [ ] **Updated Requirements Analysis**: Web UI and integration needs

#### ğŸ—ï¸ **Phase 1: Foundation** (0/4 completed)
- [ ] **Database Schema Migration**: Multi-competitor normalized schema
- [ ] **Queue System Implementation**: Celery + Redis setup
- [ ] **Deduplication System**: URL and content duplicate prevention
- [ ] **Enhanced Apify Integration**: Field mapping and processing

#### ğŸ” **Phase 2: Core Pipeline** (0/4 completed)
- [ ] **Discovery Engine**: Stage 1 URL discovery system
- [ ] **Engagement Engine**: Stage 2 metrics extraction system
- [ ] **Content Processing**: Advanced content analysis
- [ ] **Basic Web Framework**: Foundation for UI components

#### ğŸ–¥ï¸ **Phase 3: Web Interface** (0/5 completed)
- [ ] **Competitor Management UI**: Add/edit/delete competitors
- [ ] **Keyword Management UI**: Manage keywords per competitor/platform
- [ ] **Manual URL Interface**: Submit URLs for processing
- [ ] **Channel Monitoring UI**: Monitor social media accounts
- [ ] **Real-time Dashboard**: Live status and analytics

#### ğŸ“Š **Phase 4: Advanced Features** (0/4 completed)
- [ ] **Source Monitoring Automation**: Scheduled monitoring jobs
- [ ] **Analytics Engine**: Metrics, trends, competitive intelligence
- [ ] **Mobile Optimization**: Responsive design for all devices
- [ ] **Performance Tuning**: Optimization for production load

#### ğŸ§ª **Phase 5: Testing & Deployment** (0/4 completed)
- [ ] **Testing Suite**: Unit, integration, and load tests
- [ ] **Quality Assurance**: Data validation and error handling
- [ ] **Production Setup**: Deployment configuration
- [ ] **Documentation**: User guides and API documentation

---

*This action plan is actively updated as implementation progresses. Each checkbox represents a specific deliverable.*